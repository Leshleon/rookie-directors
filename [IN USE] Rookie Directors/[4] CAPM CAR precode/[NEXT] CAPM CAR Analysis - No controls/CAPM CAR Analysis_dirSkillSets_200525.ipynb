{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b458c8c-8cfd-46bc-b42f-9bdfca727e23",
   "metadata": {},
   "source": [
    "# Director Skill Sets Table 7 - Departures only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74a3240-1fcb-4db2-a909-782a5a6e0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web #to collect data\n",
    "import datetime as dt #to specify start and end dates\n",
    "\n",
    "# import yfinance as yf\n",
    "\n",
    "import eventstudy as es\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mpl_toolkits as mplot3d\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "from patsy import dmatrices\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816d638e-5858-4293-a3f8-ca898aa4369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_folder_path = rf\"C:\\Users\\SHIVAM\\Desktop\\Finance\\Kavitha Ranganathan TAPMI\\Rookie Directors Project\\Data Analysis\\Data Analysis\\[IN USE] Rookie Directors\\CAPM CAR precode\\car_output4\"\n",
    "output_folder_path = \"analysis_outputs\"\n",
    "pca_input_folder_path = rf\"C:\\Users\\SHIVAM\\Desktop\\Finance\\Kavitha Ranganathan TAPMI\\Rookie Directors Project\\Data Analysis\\Data Analysis\\[IN USE] Rookie Directors\\Director Skills PCA\\director_skills_pca\"\n",
    "supporting_folder_path = \"supporting_datafiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c1f37f-755c-453e-8ae4-e5a9b69a812d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dirFirm0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_folder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDirector Level_MF_CAR.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m pca \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpca_input_folder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMain_Director_COMPLETE_PCA.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m pca_col \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson Code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsOnDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkillsetIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkillsetGeneralistDummy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC1_FactorScore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC1_FactorScore_Standardised\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m ]\n\u001b[0;32m     10\u001b[0m pca2 \u001b[38;5;241m=\u001b[39m pca[pca_col]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\pickle.py:206\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;66;03m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[1;32m--> 206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:1851\u001b[0m, in \u001b[0;36m_frombuffer\u001b[1;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m _fromfunction_with_like \u001b[38;5;241m=\u001b[39m array_function_dispatch()(fromfunction)\n\u001b[1;32m-> 1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frombuffer\u001b[39m(buf, dtype, shape, order):\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m frombuffer(buf, dtype\u001b[38;5;241m=\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mreshape(shape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misscalar\u001b[39m(element):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dirFirm0 = pd.read_pickle(rf\"{import_folder_path}\\Director Level_MF_CAR.pkl\")\n",
    "pca = pd.read_pickle(rf\"{pca_input_folder_path}\\Main_Director_COMPLETE_PCA.pkl\")\n",
    "\n",
    "pca_col = [\n",
    "    \"Person Code\", \"AsOnDate\", \"Symbol\",\n",
    "    \"SkillsetIndex\", \"SkillsetGeneralistDummy\",\n",
    "    \"PC1_FactorScore\", \"PC1_FactorScore_Standardised\"\n",
    "]\n",
    "\n",
    "pca2 = pca[pca_col].copy()\n",
    "dirFirm = dirFirm0.merge(pca2, on = [\"Person Code\", \"AsOnDate\", \"Symbol\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5bf91-fd8a-4360-b33c-14e26f36a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirFirm data wrangling if any:\n",
    "dirFirm[\"Appointment Year\"] = [x.year for x in dirFirm[\"Appointment Date\"]]\n",
    "\n",
    "dirFirm = dirFirm.drop_duplicates(subset = [\"Person Code\", \"Company\", \"Appointment Date\"]).reset_index(drop = True)\n",
    "\n",
    "dirFirm[\"ln_dirage\"] = np.log(dirFirm[\"Age\"] + 1).astype(\"float\")\n",
    "dirFirm[\"ln_directorships\"] = np.log(dirFirm[\"CompCountOtherPastTotalAB\"] + 1).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b76d3d-7699-47f7-a771-e95e187d439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirFirm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca0963-05b0-4bdb-99c8-d5a1b4b955af",
   "metadata": {},
   "source": [
    "# PSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a563a-5032-4a34-a794-2a86505ddf6f",
   "metadata": {},
   "source": [
    "## Verifying and removing those rows with no control data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf546e8-b6e6-4431-a109-845e37041f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample constraints ---> govtdummy==0 & findummy==0 & asonyear>2012\n",
    "dirFirm.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1cb13-e0f7-4ca3-8dd0-a364e1a7508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirFirm[\"IsDualityChairmanMD\"] = dirFirm[\"IsDualityChairmanMD\"].astype(int)\n",
    "\n",
    "\n",
    "# dirFirm[\"NIC_2digit\"] = dirFirm[\"NIC code\"].dropna().apply(lambda x: x[0:2])\n",
    "# dirFirm[\"NIC_2digit\"] = dirFirm[\"NIC_2digit\"]\n",
    "\n",
    "psmSample = dirFirm.loc[ (dirFirm[\"Appointment Date\"] >= \"2013-03-31\")].copy()\n",
    "# \\\n",
    "# & (dirFirm[\"govtdummy\"] == 0) & (dirFirm[\"findummy\"] == 0) ].copy()\n",
    "#.dropna(subset = controlVars).dropna(subset = dependentVar).copy()\n",
    "\n",
    "psmSample[\"DummySum\"] = psmSample[\"IsRookie\"] + psmSample[\"IsNonRookie\"]\n",
    "psmSample[\"DummySumIndep\"] = psmSample[\"IsRookieIndep\"] + psmSample[\"IsNonRookieIndep\"]\n",
    "\n",
    "psmSampleAll = psmSample.loc[ psmSample[\"DummySum\"] == 1 ].reset_index(drop = True)\n",
    "#psmSampleAll = psmSampleAll.loc[ ~psmSampleAll.duplicated(subset = [\"AsOnDate\", \"Symbol\", \"Appointment Date\"], keep = False)]\n",
    "\n",
    "psmSampleIndep = psmSample.loc[ psmSample[\"DummySumIndep\"] == 1 ].reset_index(drop = True)\n",
    "#psmSampleIndep = psmSampleIndep.loc[ ~psmSampleIndep.duplicated(subset = [\"AsOnDate\", \"Symbol\", \"Appointment Date\"], keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8d66a-d56d-4cd7-a26d-eb1183b2be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirFirm2 = dirFirm.copy()\n",
    "# psmSampleIndep2 = psmSampleIndep.copy()\n",
    "\n",
    "# listCol = [\n",
    "#     \"FirstYearPCodeList\", \"TwoYearPCodeList\", \"ThreeYearPCodeList\", \"PCodeList\",\n",
    "#     \"FirstYearIndepPCodeList\", \"TwoYearIndepPCodeList\", \"ThreeYearIndepPCodeList\", \"IndepPCodeList\",\n",
    "#     \"OtherFirstYearIndepPCode\", \"OtherTwoYearIndepPCode\", \"OtherThreeYearIndepPCode\", \"TotalIndepPCode\",\n",
    "#     \"OtherFirstYearPCode\", \"OtherTwoYearPCode\", \"OtherThreeYearPCode\", \"TotalPCode\",\n",
    "#     \"OtherFirstYearPCodeIndepExcl\",\"OtherTwoYearPCodeIndepExcl\", \"OtherThreeYearPCodeIndepExcl\", \"TotalPCodeIndepExcl\",\n",
    "#     \"OtherFirstYearPCodeExcl\", \"OtherTwoYearPCodeExcl\", \"OtherThreeYearPCodeExcl\", \"TotalPCodeExcl\"\n",
    "# ]\n",
    "\n",
    "# dirFirm2 = dirFirm2.drop(listCol, axis = 1)\n",
    "# psmSampleIndep2 = psmSampleIndep2.drop(listCol, axis = 1)\n",
    "\n",
    "\n",
    "# dirFirm2.to_csv(\"Main_Firm_PSM Ready_no filter v040425.csv\")\n",
    "# psmSampleIndep2.to_csv(\"Main_Firm_PSM Ready_filter-Indep_gov_fin v040425.csv\")\n",
    "\n",
    "\n",
    "# # # psmSampleAll --> 2101 rows \n",
    "# # psmSampleIndep --> 1561 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782934ae-9b7d-4725-bc13-260f55d1e317",
   "metadata": {},
   "source": [
    "## PSM --> RookieAppoints as Treatment, NonRookieAppoints as Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e55b0-a843-4e1d-b219-e63966758515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogitReg(sample, endog_var, exog_var):\n",
    "    \n",
    "    # Logit Regression\n",
    "    endog = sample[[endog_var]]\n",
    "    exog = sample[exog_var]\n",
    "    exog = sm.add_constant(exog)\n",
    "    \n",
    "    log_reg = sm.Logit(endog, exog).fit()\n",
    "\n",
    "    propensityScores = log_reg.predict(exog)\n",
    "    \n",
    "    return propensityScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c103ac5-c339-4883-802e-b1a7aaad1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanDiffTtest(sample, endog_var, exog_var, car, depVar, dirFirm):\n",
    "\n",
    "    sample[car] = winsorize(sample[car], limits = [0.01, 0.01])\n",
    "    if depVar != None:\n",
    "        dirFirm = dirFirm.rename( {depVar:f\"{depVar}_2\"}, axis = 1)\n",
    "    \n",
    "        colsAdd = []\n",
    "        for i in range(-1, 4):\n",
    "            if i != 0:\n",
    "                colsAdd.append(f\"AsOnYear_T+{i}\")\n",
    "                colsAdd.append(f\"{depVar}T+{i}\")\n",
    "                if i>0 :\n",
    "                    colsAdd.append(depVar+f\"(T+{i}) - (T-1)\")\n",
    "    \n",
    "        newFrame= pd.DataFrame(columns = colsAdd, data = 0, index = sample.index, dtype = \"int\")\n",
    "        sample = pd.concat([sample, newFrame], axis = 1)\n",
    "        sample = sample.copy()\n",
    "        \n",
    "        for i in range(-1, 4):\n",
    "            if i != 0:\n",
    "                sample.loc[:, f\"AsOnYear_T+{i}\"] = sample[\"AsOnYear\"] + i\n",
    "    \n",
    "        for i in range(-1, 4):\n",
    "            if i != 0:\n",
    "                sample.loc[:, f\"{depVar}T+{i}\"] = sample.merge(dirFirm[[\"Symbol\", \"AsOnYear\", f\"{depVar}_2\"]].copy(), left_on = [\"Symbol\", f\"AsOnYear_T+{i}\"],\n",
    "                                                              right_on = [\"Symbol\", \"AsOnYear\"], how = \"left\")[f\"{depVar}_2\"]\n",
    "        \n",
    "        for i in range(1, 4):\n",
    "            if i != 0:\n",
    "                sample.loc[:, depVar+f\"(T+{i}) - (T-1)\"] = sample[f\"{depVar}T+{i}\"] - sample[f\"{depVar}T+-1\"]\n",
    "    \n",
    "            \n",
    "        sample = sample.copy()\n",
    "    \n",
    "    group1 = sample.loc[ sample[endog_var] == 1].copy()\n",
    "    group2 = sample.loc[ sample[endog_var] == 0].copy()\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(group1[car], group2[car], equal_var=False)  # Welch’s t-test (default)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(car, \":\")\n",
    "    print(\"\\n\")\n",
    "    print(\"T Statistic:\", t_stat, \" P Value:\",p_value)\n",
    "    print(\"Treated Mean:\", group1[car].mean(), \" Control Mean:\", group2[car].mean(), \" Diff:\", group1[car].mean() - group2[car].mean())\n",
    "    print(\"Treated Median:\", group1[car].median(), \" Control Median:\", group2[car].median(), \" Diff:\", group1[car].median() - group2[car].median())\n",
    "    print(\"Treated N:\", len(group1[car]), \"; Control N:\", len(group2[car]))\n",
    "    print(\"[treated unique = \", len(group1.loc[ :, [\"Person Code\", \"Symbol\", \"AsOnDate\"]].drop_duplicates()), \"]\",\\\n",
    "          \"[control unique = \", len(group2.loc[ :, [\"Person Code\", \"Symbol\", \"AsOnDate\"]].drop_duplicates()), \"]\"\n",
    "         )\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    if exog_var != None:\n",
    "        print(\"━\"*120)\n",
    "        print(f'{\"Matching Variable\":<40} {\"Treatment Firms\":<20} {\"Control Firms\":<20} {\"Test of Diff (p value)\":<20}')\n",
    "        print(f'{\" \":<40} {\"N = \" + str(len(group1[car])):<20} {\"N = \" + str(len(group2[car])):<20}')\n",
    "        print(\"-\"*120)\n",
    "\n",
    "        for var in exog_var:\n",
    "            treatMean = group1[var].mean()\n",
    "            controlMean = group2[var].mean()\n",
    "            p_value = stats.ttest_ind(group1[var], group2[var], equal_var=False)[1]\n",
    "            print(f'{var:<40} {treatMean:<20.4f} {controlMean:<20.4f} {p_value:<20.4f}')\n",
    "    \n",
    "        print(\"━\"*120, \"\\n\")\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    if depVar != None:\n",
    "        print(depVar, \" across years:\\n\")\n",
    "        for i in range(1,4):\n",
    "            sample = sample.dropna(subset = [depVar+f'(T+{i}) - (T-1)'])\n",
    "    \n",
    "        group1 = sample.loc[ sample[endog_var] == 1].copy()\n",
    "        group2 = sample.loc[ sample[endog_var] == 0].copy()\n",
    "\n",
    "        print(\"━\"*150, \"\\n\")\n",
    "        print(f'{depVar:<40}{\" \":<20}{\"Treatment Firms\":<20}{\"Control Firms\":<20}{\"Difference\":<20}{\"Test of Diff\":<20}{\"Test of Diff\"}')\n",
    "        print(f'{\" \":<120}{\"(t stat)\":<20}{\"(p value)\":<20}')\n",
    "    \n",
    "        print(\"─\"*150, \"\\n\")\n",
    "    \n",
    "        for i in range(1,4):\n",
    "            t_stat2, p_value2 = stats.ttest_ind(group1[depVar+f'(T+{i}) - (T-1)'], group2[depVar+f'(T+{i}) - (T-1)'], equal_var=False)  # Welch’s t-test (default)\n",
    "            \n",
    "            treatedMean = group1[depVar+f'(T+{i}) - (T-1)'].mean()\n",
    "            controlMean = group2[depVar+f'(T+{i}) - (T-1)'].mean()\n",
    "            diffMean = treatedMean - controlMean\n",
    "    \n",
    "            treatedMedian = group1[depVar+f'(T+{i}) - (T-1)'].median()\n",
    "            controlMedian = group2[depVar+f'(T+{i}) - (T-1)'].median()\n",
    "            diffMedian = treatedMedian - controlMedian\n",
    "    \n",
    "            print(f'{\"Year_T+\" + str(i) +\" - Year_T-1\":<40}{\"<MEAN>\":<20}{treatedMean:<20.4f}{controlMean:<20.4f}{diffMean:<20.4f}{t_stat2:<20.4f}{p_value2:<20.10f}')\n",
    "    \n",
    "            label1 = \"Treated N: \" + str(len(group1[depVar+f'(T+{i}) - (T-1)']))\n",
    "            label2 = \"Control N: \" + str(len(group2[depVar+f'(T+{i}) - (T-1)']))\n",
    "            \n",
    "            print(f'{label1 + \" \"*5 + label2:<40}{\"<MEDIAN>\":<20}{treatedMedian:<20.4f}{controlMedian:<20.4f}{diffMedian:<20.4f}')\n",
    "            \n",
    "            print(\"-\"*150, \"\\n\")\n",
    "            \n",
    "        print(\"━\"*150, \"\\n\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e66405-4996-4b58-9f3a-93e6c4fd94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneSampleTtest(sample, endog_var, exog_var, car, depVar, dirFirm):\n",
    "\n",
    "    # if depVar != None:\n",
    "    #     dirFirm = dirFirm.rename( {depVar:f\"{depVar}_2\"}, axis = 1)\n",
    "    \n",
    "    #     colsAdd = []\n",
    "    #     for i in range(-1, 4):\n",
    "    #         if i != 0:\n",
    "    #             colsAdd.append(f\"AsOnYear_T+{i}\")\n",
    "    #             colsAdd.append(f\"{depVar}T+{i}\")\n",
    "    #             if i>0 :\n",
    "    #                 colsAdd.append(depVar+f\"(T+{i}) - (T-1)\")\n",
    "    \n",
    "    #     newFrame= pd.DataFrame(columns = colsAdd, data = 0, index = sample.index, dtype = \"int\")\n",
    "    #     sample = pd.concat([sample, newFrame], axis = 1)\n",
    "    #     sample = sample.copy()\n",
    "        \n",
    "    #     for i in range(-1, 4):\n",
    "    #         if i != 0:\n",
    "    #             sample.loc[:, f\"AsOnYear_T+{i}\"] = sample[\"AsOnYear\"] + i\n",
    "    \n",
    "    #     for i in range(-1, 4):\n",
    "    #         if i != 0:\n",
    "    #             sample.loc[:, f\"{depVar}T+{i}\"] = sample.merge(dirFirm[[\"Symbol\", \"AsOnYear\", f\"{depVar}_2\"]].copy(), left_on = [\"Symbol\", f\"AsOnYear_T+{i}\"],\n",
    "    #                                                           right_on = [\"Symbol\", \"AsOnYear\"], how = \"left\")[f\"{depVar}_2\"]\n",
    "        \n",
    "    #     for i in range(1, 4):\n",
    "    #         if i != 0:\n",
    "    #             sample.loc[:, depVar+f\"(T+{i}) - (T-1)\"] = sample[f\"{depVar}T+{i}\"] - sample[f\"{depVar}T+-1\"]\n",
    "    \n",
    "            \n",
    "    #     sample = sample.copy()\n",
    "    sample[car] = winsorize(sample[car], limits = [0.01, 0.01])\n",
    "    group1 = sample.copy()\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_1samp(group1[car], 0)  # Welch’s t-test (default)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(car, \":\")\n",
    "    print(\"\\n\")\n",
    "    print(\"T Statistic:\", t_stat, \" P Value:\",p_value)\n",
    "    print(\"Mean:\", group1[car].mean())\n",
    "    print(\"Median:\", group1[car].median())\n",
    "    print(\"N:\", len(group1[car]))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # if exog_var != None:\n",
    "    #     print(\"━\"*120)\n",
    "    #     print(f'{\"Matching Variable\":<40} {\"Treatment Firms\":<20} {\"Control Firms\":<20} {\"Test of Diff (p value)\":<20}')\n",
    "    #     print(f'{\" \":<40} {\"N = \" + str(len(group1[car])):<20} {\"N = \" + str(len(group2[car])):<20}')\n",
    "    #     print(\"-\"*120)\n",
    "\n",
    "    #     for var in exog_var:\n",
    "    #         treatMean = group1[var].mean()\n",
    "    #         controlMean = group2[var].mean()\n",
    "    #         p_value = stats.ttest_ind(group1[var], group2[var], equal_var=False)[1]\n",
    "    #         print(f'{var:<40} {treatMean:<20.4f} {controlMean:<20.4f} {p_value:<20.4f}')\n",
    "    \n",
    "    #     print(\"━\"*120, \"\\n\")\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # if depVar != None:\n",
    "    #     print(depVar, \" across years:\\n\")\n",
    "    #     for i in range(1,4):\n",
    "    #         sample = sample.dropna(subset = [depVar+f'(T+{i}) - (T-1)'])\n",
    "    \n",
    "    #     group1 = sample.loc[ sample[endog_var] == 1].copy()\n",
    "    #     group2 = sample.loc[ sample[endog_var] == 0].copy()\n",
    "\n",
    "    #     print(\"━\"*150, \"\\n\")\n",
    "    #     print(f'{depVar:<40}{\" \":<20}{\"Treatment Firms\":<20}{\"Control Firms\":<20}{\"Difference\":<20}{\"Test of Diff\":<20}{\"Test of Diff\"}')\n",
    "    #     print(f'{\" \":<120}{\"(t stat)\":<20}{\"(p value)\":<20}')\n",
    "    \n",
    "    #     print(\"─\"*150, \"\\n\")\n",
    "    \n",
    "    #     for i in range(1,4):\n",
    "    #         t_stat2, p_value2 = stats.ttest_ind(group1[depVar+f'(T+{i}) - (T-1)'], group2[depVar+f'(T+{i}) - (T-1)'], equal_var=False)  # Welch’s t-test (default)\n",
    "            \n",
    "    #         treatedMean = group1[depVar+f'(T+{i}) - (T-1)'].mean()\n",
    "    #         controlMean = group2[depVar+f'(T+{i}) - (T-1)'].mean()\n",
    "    #         diffMean = treatedMean - controlMean\n",
    "    \n",
    "    #         treatedMedian = group1[depVar+f'(T+{i}) - (T-1)'].median()\n",
    "    #         controlMedian = group2[depVar+f'(T+{i}) - (T-1)'].median()\n",
    "    #         diffMedian = treatedMedian - controlMedian\n",
    "    \n",
    "    #         print(f'{\"Year_T+\" + str(i) +\" - Year_T-1\":<40}{\"<MEAN>\":<20}{treatedMean:<20.4f}{controlMean:<20.4f}{diffMean:<20.4f}{t_stat2:<20.4f}{p_value2:<20.10f}')\n",
    "    \n",
    "    #         label1 = \"Treated N: \" + str(len(group1[depVar+f'(T+{i}) - (T-1)']))\n",
    "    #         label2 = \"Control N: \" + str(len(group1[depVar+f'(T+{i}) - (T-1)']))\n",
    "            \n",
    "    #         print(f'{label1 + \" \"*5 + label2:<40}{\"<MEDIAN>\":<20}{treatedMedian:<20.4f}{controlMedian:<20.4f}{diffMedian:<20.4f}')\n",
    "            \n",
    "    #         print(\"-\"*150, \"\\n\")\n",
    "            \n",
    "    #print(\"━\"*150, \"\\n\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61075f3-4709-485d-8e56-c772b6b41fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PsmReplac(sample, endog_var, exog_var, car, depVar, dirFirm):\n",
    "\n",
    "    # Logit Regression\n",
    "    sample.loc[:, \"propensityScore\"] = LogitReg(sample, endog_var, exog_var)\n",
    "\n",
    "    treated = sample.loc[ sample[endog_var] == 1].copy()\n",
    "    control = sample.loc[ sample[endog_var] == 0].copy()\n",
    "\n",
    "    # Nearest Neighbours\n",
    "    nn = NearestNeighbors(n_neighbors = 1, metric = \"euclidean\")\n",
    "    nn.fit(control[[\"propensityScore\"]])\n",
    "\n",
    "    distances, indices = nn.kneighbors(treated[[\"propensityScore\"]])\n",
    "    \n",
    "    matchedControl = control.iloc[indices.flatten()].copy()\n",
    "    \n",
    "    matched = pd.concat([treated, matchedControl])\n",
    "    matched.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    MeanDiffTtest(matched, endog_var, exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62af08-6c43-4eeb-930c-6fb756761f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Func PSM non replacement\n",
    "def PsmNonReplac(sample, endog_var, exog_var, car, depVar, dirFirm):\n",
    "\n",
    "    # Logit Regression\n",
    "    sample.loc[:, \"propensityScore\"] = LogitReg(sample, endog_var, exog_var)\n",
    "\n",
    "    # Separate treated and control groups\n",
    "    treated = sample[sample[endog_var] == 1].copy()\n",
    "    control = sample[sample[endog_var] == 0].copy()\n",
    "    \n",
    "    # Compute pairwise distances (absolute difference in propensity scores)\n",
    "    dist_matrix = cdist(treated[['propensityScore']], control[['propensityScore']], metric='euclidean')\n",
    "    \n",
    "    # Match without replacement\n",
    "    treated_indices = []\n",
    "    matched_indices = []\n",
    "    used_control_indices = set()\n",
    "    \n",
    "    for i in range(len(treated)):\n",
    "        if len(used_control_indices) >= len(control):  # Stop if no controls left\n",
    "            print(\"Warning: Not enough control units to match all treated units.\")\n",
    "            break\n",
    "        \n",
    "        # Get nearest control unit index that hasn't been used\n",
    "        match_idx = np.argmin(dist_matrix[i])\n",
    "        \n",
    "        while match_idx in used_control_indices:  # Ensure it's not already matched\n",
    "            dist_matrix[i, match_idx] = np.inf  # Temporarily set distance to infinity\n",
    "\n",
    "            if np.all(dist_matrix[i] == np.inf):  # If all controls are exhausted\n",
    "                print(f\"No available control for treated unit {i}, skipping.\")\n",
    "                match_idx = None\n",
    "                break\n",
    "            \n",
    "            match_idx = np.argmin(dist_matrix[i])\n",
    "        \n",
    "        used_control_indices.add(match_idx)\n",
    "        matched_indices.append(match_idx)\n",
    "        treated_indices.append(i)\n",
    "    \n",
    "    # Retrieve matched units\n",
    "    matched_control = control.iloc[matched_indices].copy()\n",
    "    matched_treated = treated.iloc[treated_indices].copy()\n",
    "    \n",
    "    # Combine matched treated and control units\n",
    "    matched_data = pd.concat([matched_treated.reset_index(drop=True), matched_control.reset_index(drop=True)])\n",
    "    \n",
    "    # Reset index\n",
    "    matched_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # Mean difference and T Test\n",
    "    MeanDiffTtest(matched_data, endog_var, exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d9c1b-0681-456a-840a-04cf825a7c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f97f5-0277-4f8d-a8c0-35141fd7282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "psmSampleIndep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a284686-c37e-4873-9106-0080b8bca7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7a4d3bf-c7cc-43b2-b76e-a577f37a85be",
   "metadata": {},
   "source": [
    "# CAR Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b08fdc-d375-4de5-b172-a4eb2f9a9b6f",
   "metadata": {},
   "source": [
    "### Total Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f2e28-d8ed-49db-8344-8803cc8c2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = psmSampleIndep.copy()\n",
    "\n",
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "for car in carCol:\n",
    "    test[car] = winsorize(test[car].values, limits = [0.01, 0.01]).data\n",
    "    test[[car, \"Appointment Year\"]].plot(kind = \"scatter\", x=\"Appointment Year\", y=car, xticks = np.arange(2012, 2025, step = 1), yticks = np.arange(-2, 2.25, step = 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831a9da-9be9-4f3a-8199-dcd9dca21cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cad9aa-068e-4793-b3af-901d835c409f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d36ef0c-72fe-4dd0-a85c-826045a2c2cc",
   "metadata": {},
   "source": [
    "### RID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea00fd0-b66a-4147-9830-5e781b05823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = psmSampleIndep.loc[ psmSampleIndep[\"IsRookieIndep\"] == 1 ].copy()\n",
    "\n",
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "for car in carCol:\n",
    "    test[car] = winsorize(test[car].values, limits = [0.01, 0.01]).data\n",
    "    test[[car, \"Appointment Year\"]].plot(kind = \"scatter\", x=\"Appointment Year\", y=car, xticks = np.arange(2012, 2025, step = 1), yticks = np.arange(-2, 2.25, step = 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ca743-f430-4f83-9ec2-db0346e1c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735c14f-9de2-41a7-85eb-b04d96d402a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[ test[\"120CAR5\"] >= 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37885dd-b7e8-4ede-b4c8-b2e9f26d5294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d7d3f-4ca9-4319-bec1-389a9aaef3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff57950-a337-4a3c-97f5-591cbff59c74",
   "metadata": {},
   "source": [
    "### Non RID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf03d86-8def-46e4-8132-87aa29df84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = psmSampleIndep.loc[ psmSampleIndep[\"IsRookieIndep\"] == 0 ].copy()\n",
    "\n",
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "for car in carCol:\n",
    "    test[car] = winsorize(test[car].values, limits = [0.01, 0.01]).data\n",
    "    test[[car, \"Appointment Year\"]].plot(kind = \"scatter\", x=\"Appointment Year\", y=car, xticks = np.arange(2012, 2025, step = 1), yticks = np.arange(-2, 2.25, step = 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648defb1-6a35-493d-9672-8998f324d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32bcda-fa86-4114-88c0-ef6688a3dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[ test[\"180CAR11\"] >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d9345-2c05-4d88-9bc4-270012de5292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7cba1-0af9-49ad-8bcd-769845e2d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e4e75-0305-4672-a486-45ea3ca0d5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f9d4a-da87-4193-9bac-f036f12a0fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd7b2d-e5ef-4511-ae5b-e1dd5fdd607d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea041ee1-c50e-4f03-bdbc-00174e6cb71d",
   "metadata": {},
   "source": [
    "## Panel A: Whole Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a298df7-1d68-4ea7-9740-04b4f06f27f3",
   "metadata": {},
   "source": [
    "### Mean Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19f458-a04c-4023-ae5a-f958820380db",
   "metadata": {},
   "outputs": [],
   "source": [
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "exog_var = None\n",
    "depVar = None\n",
    "controlVars = None\n",
    "\n",
    "for car in carCol:\n",
    "    sample = psmSampleIndep.dropna(subset = car).reset_index(drop=True).copy()\n",
    "    MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c951d-65cd-4201-877d-4ff197eaa8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07e5b3-ceb9-4ba9-863c-35368a40581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PSM without replacement\n",
    "# PsmNonReplac(psmSampleIndep, \"RookieIndepAppointDummy\", controlVars, \"ln_TobinQ_longborrowincl2\", dirFirm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051b5a5-0555-4dd4-a1ba-04cf4fc7d03e",
   "metadata": {},
   "source": [
    "### One Sample T Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c726ba-e6de-4cb2-8020-7f44b7491f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "exog_var = None\n",
    "depVar = None\n",
    "controlVars = None\n",
    "\n",
    "for car in carCol:\n",
    "    sample1 = psmSampleIndep.loc[psmSampleIndep[\"IsRookieIndep\"] == 1].copy()\n",
    "    print(\"Rookie Independent Directors:\")\n",
    "    sample = sample1.dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    sample2 = psmSampleIndep.loc[psmSampleIndep[\"IsRookieIndep\"] == 0].copy()\n",
    "    print(\"Non Rookie Independent Directors:\")\n",
    "    sample = sample2.dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125785e4-71c2-4473-9ff3-656b488b415f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f4a4be3-9625-4e84-9773-261ea38c308b",
   "metadata": {},
   "source": [
    "## Panel B: Unique skills dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc0a7d-4f27-4cc2-89fe-a5a6bb08ba4e",
   "metadata": {},
   "source": [
    "### Mean Difference: RID vs NRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f68a80-ddf4-45ed-892b-f2037029128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "exog_var = None\n",
    "depVar = None\n",
    "controlVars = None\n",
    "\n",
    "for car in carCol:\n",
    "    print(\"No unique skills:\")\n",
    "    sample = psmSampleIndep.loc[psmSampleIndep[\"NumSkills_dummies\"] == 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    print(\"At least one unique skill:\")\n",
    "    sample = psmSampleIndep.loc[psmSampleIndep[\"NumSkills_dummies\"] != 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54d553-e18e-412a-b69a-65e846a87a8b",
   "metadata": {},
   "source": [
    "### Mean Difference: within RID/NRID: WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9af36a-ca3e-4c7f-8359-08e674e06408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "#           \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "#           \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "#           \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "# exog_var = None\n",
    "# depVar = None\n",
    "# controlVars = None\n",
    "\n",
    "# for car in carCol:\n",
    "#     print(\"No unique skills:\")\n",
    "#     sample = psmSampleIndep.loc[psmSampleIndep[\"NumSkills_dummies\"] == 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "#     MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "#     print(\"At least one unique skill:\")\n",
    "#     sample = psmSampleIndep.loc[psmSampleIndep[\"NumSkills_dummies\"] != 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "#     MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e61d9b-3220-4e5f-8619-8c0ab24d4362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cee72f7-1ae6-4f8b-b09a-6a20109b1330",
   "metadata": {},
   "source": [
    "### One Sample T Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05574409-fa3d-4d80-ac9b-cb42af8818ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "exog_var = None\n",
    "depVar = None\n",
    "controlVars = None\n",
    "\n",
    "for car in carCol:\n",
    "    sample1 = psmSampleIndep.loc[psmSampleIndep[\"IsRookieIndep\"] == 1].copy()\n",
    "    print(\"Rookie Independent Directors\\nNo unique skills:\")\n",
    "    sample = sample1.loc[sample1[\"NumSkills_dummies\"] == 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    print(\"At least one unique skill:\")\n",
    "    sample = sample1.loc[sample1[\"NumSkills_dummies\"] != 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    sample2 = psmSampleIndep.loc[psmSampleIndep[\"IsRookieIndep\"] == 0].copy()\n",
    "    print(\"Non Rookie Independent Directors\\nNo unique skills:\")\n",
    "    sample = sample2.loc[sample2[\"NumSkills_dummies\"] == 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    print(\"At least one unique skill:\")\n",
    "    sample = sample2.loc[sample2[\"NumSkills_dummies\"] != 0].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cdd86-5890-4c9f-a9c0-d3ac4202b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PSM without replacement\n",
    "# PsmNonReplac(psmSampleIndep, \"RookieIndepAppointDummy\", controlVars, \"ln_TobinQ_longborrowincl2\", dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa56bc6-251f-4933-b356-43268a854889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98ddce26-ff36-4b51-8529-6b0fe236e786",
   "metadata": {},
   "source": [
    "## Panel C: Number of Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37bd46-7a45-443d-9129-73216d14dbab",
   "metadata": {},
   "source": [
    "### Mean Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4394df7-b05c-43b3-bf28-17620ab00446",
   "metadata": {},
   "outputs": [],
   "source": [
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "exog_var = None\n",
    "depVar = None\n",
    "controlVars = None\n",
    "\n",
    "num_skills_median = psmSampleIndep.drop_duplicates(subset = [\"AsOnDate\", \"Person Code\"])[\"NumSkills_dummies\"].median()\n",
    "for car in carCol:\n",
    "    print(\"Less than median no. skills:\")\n",
    "    sample = psmSampleIndep.loc[psmSampleIndep[\"NumSkills_dummies\"] < num_skills_median].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    print(\"Greater than median no. skills:\")\n",
    "    sample = psmSampleIndep.loc[psmSampleIndep[\"NumSkills_dummies\"] > num_skills_median].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    MeanDiffTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbd410-e1c7-48d5-9970-ad43f7f92ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65ad2b6e-d4a0-4401-bf9b-9519590e936c",
   "metadata": {},
   "source": [
    "### One Sample T Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42f3b3-afa4-4aa5-a1d4-c014000c5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "carCol = [\"120CAR3\", \"120CAR5\", \"120CAR7\", \"120CAR11\", \n",
    "          \"150CAR3\", \"150CAR5\", \"150CAR7\", \"150CAR11\", \n",
    "          \"180CAR3\", \"180CAR5\", \"180CAR7\", \"180CAR11\",\n",
    "          \"210CAR3\", \"210CAR5\", \"210CAR7\", \"210CAR11\"]\n",
    "\n",
    "exog_var = None\n",
    "depVar = None\n",
    "controlVars = None\n",
    "\n",
    "num_skills_median = psmSampleIndep.drop_duplicates(subset = [\"AsOnDate\", \"Person Code\"])[\"NumSkills_dummies\"].median()\n",
    "for car in carCol:\n",
    "    sample1 = psmSampleIndep.loc[psmSampleIndep[\"IsRookieIndep\"] == 1].copy()\n",
    "    print(\"Rookie Independent Directors\\nLess than median no. skills:\")\n",
    "    sample = sample1.loc[sample1[\"NumSkills_dummies\"] < num_skills_median].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    print(\"Greater than median no. skills:\")\n",
    "    sample = sample1.loc[sample1[\"NumSkills_dummies\"] < num_skills_median].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    sample2 = psmSampleIndep.loc[psmSampleIndep[\"IsRookieIndep\"] == 0].copy()\n",
    "    print(\"Non Rookie Independent Directors\\nLess than median no. skills:\")\n",
    "    sample = sample2.loc[sample2[\"NumSkills_dummies\"] > num_skills_median].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)\n",
    "\n",
    "    print(\"Greater than median no. skills:\")\n",
    "    sample = sample2.loc[sample2[\"NumSkills_dummies\"] > num_skills_median].dropna(subset = car).reset_index(drop=True).copy()\n",
    "    OneSampleTtest(sample, \"IsRookieIndep\", exog_var, car, depVar, dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f8562-8847-4148-b94b-e24e3b05e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PSM without replacement\n",
    "# PsmNonReplac(psmSampleIndep, \"RookieIndepAppointDummy\", controlVars, \"ln_TobinQ_longborrowincl2\", dirFirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0189758-9a42-4692-9dc2-7cf23e66a6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97629930-a4fd-4ee6-bb94-b5f79526eaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868fc9c-46d8-4ad5-a813-c7a8cd095def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7df4b-78d6-4c7a-9e7f-0c0372ec5164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
